{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from smolagents import HfApiModel, CodeAgent, DuckDuckGoSearchTool\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HfApiModel(token=os.getenv(\"HF_ACCESS_TOKEN\"),model_id='meta-llama/Llama-3.2-3B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭────────────────────────────────────────────────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ───────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">how fast can we travel from mumbai to delhi</span>                                                                                                                                                          <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mhow fast can we travel from mumbai to delhi\u001b[0m                                                                                                                                                          \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">search_results </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_search(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"fastest travel time from Mumbai to Delhi\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                   </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(search_results)</span><span style=\"background-color: #272822\">                                                                                                                                                                           </span> │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msearch_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_search\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mfastest travel time from Mumbai to Delhi\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34msearch_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                           \u001b[0m │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "## Search Results\n",
       "\n",
       "[Mumbai to Delhi - 5 ways to travel via train, plane, bus, and car](https://www.rome2rio.com/s/Mumbai/Delhi)\n",
       "The best way to get from Mumbai to Delhi is to fly which takes 3h 57m and costs ₹3,500 - ₹8,000. Alternatively, you can train, which costs ₹600 - ₹17,000 and takes 15h 32m, you could also bus, which \n",
       "costs and takes 29h 12m.\n",
       "\n",
       "[MUMBAI CENTRAL (MMCT) to NEW DELHI (NDLS) Trains: Tickets ... - RailYatri](https://www.railyatri.in/mumbai-central-to-new-delhi-trains)\n",
       "Mumbai Central to New Delhi train time. The Mumbai Central to New Delhi train takes between 15 Hours 32 Minutes to 28 Hours 10 Minutes. The traveller can select a train based on their preferences \n",
       "among every day trains such as Mumbai Central - New Delhi Rajdhani Express (12951), August Kranti Rajdhani Express (12953), Maharashtra Sampark Kranti Express (12907), Mumbai CSMT - Hazrat Nizamuddin \n",
       "...\n",
       "\n",
       "[Mumbai to Delhi - Multiple Options To Reach By Flight ... - MakeMyTrip](https://www.makemytrip.com/routeplanner/mumbai-delhi.html)\n",
       "The fastest way to reach Delhi from Mumbai is by Flight. It takes approximately 3 hours. The cheapest way to reach Delhi from Mumbai is by Train which would take approximately 25 hours. ... Approx \n",
       "Travel Time. 1d 1h 15m ₹605. Onwards. BOOK TRAIN. Via Jaipur. Mumbai. Jaipur. Delhi. Approx Travel Time. 4h 10m ₹9,117. Onwards. Details. Mumbai ...\n",
       "\n",
       "[Mumbai To Delhi Trains | Book From 33 Trains, Timetable, Fare - MakeMyTrip](https://www.makemytrip.com/railways/mumbai-delhi-train-tickets.html)\n",
       "Travel time by train between Mumbai to Delhi is 15h 35m. ... Want to travel from Mumbai to Delhi? Know about the trains running on this route. Some of the trains that run on this route are Hwh CSMT \n",
       "ASR EXPRESS (11057),PUNJAB MAIL (12137),LTT HW AC EXP (12171),DEE GARIBRATH (12216) etc. ... Choose MMT for the best Mumbai to Delhi train ticket ...\n",
       "\n",
       "[Mumbai to Delhi Trains: Here are the Best Ones - TripSavvy](https://www.tripsavvy.com/trains-from-mumbai-to-delhi-1539622)\n",
       "Best Mumbai to Delhi Trains . The 12951 Mumbai Central - New Delhi Rajdhani Express departs Mumbai Central at 5 p.m. and arrives at New Delhi Railway Station at 8.35 a.m. the next morning. There are \n",
       "six stops on the way. The fare in 1AC (first class, air conditioned, sleeper) is 4,760 rupees. 2A (two tier, air conditioned, sleeper) is a minimum of 2,830 rupees and a maximum of 4,073 rupees. 3A \n",
       "...\n",
       "\n",
       "[Mumbai to Delhi Trains | Book from 16 Trains, Fare, Time Table - ixigo](https://www.ixigo.com/by-train-rail/mumbai-to-delhi-by-train)\n",
       "The fastest train to Delhi from Mumbai is 12951 NDLS TEJAS RAJ.From Mumbai, the train takes 15hr 32min hours to reach Delhi. The train starts at 17:00:00 from Mumbai CSTM and reaches Delhi NDLS at \n",
       "08:32:00. 12951 NDLS TEJAS RAJ operates on Mon, Tues, Wed, Thur, Fri, Sat, Sun.\n",
       "\n",
       "[12951 - Mumbai Central New Delhi Rajdhani Express - RailYatri](https://www.railyatri.in/trains/route-12951-mumbai-central-new-delhi-rajdhani-express)\n",
       "This train runs between Mumbai Central to New Delhi and covers a total distance of 1384.0km in just 15h:32m. ... Arrival Time Stop Travel Time; 22209 - Mumbai Central New Delhi Duronto Express: 23:10 \n",
       "15:55 5 16h 45m Popular Trains from Mumbai Central. Train Number and Name ...\n",
       "\n",
       "[MUMBAI CST (CSTM) to NEW DELHI (NDLS) Trains: Tickets, Fare and ...](https://www.railyatri.in/mumbai-cst-to-new-delhi-trains)\n",
       "Mumbai Cst to New Delhi Train Ticket Booking. Mumbai Cst and New Delhi are approximately 1345 kilometers away from one another. The first train from Mumbai Cst to New Delhi leaves at 00:20 hrs from \n",
       "Mumbai Cst.The fastest train from Mumbai Cst to New Delhi is the Mumbai Central - New Delhi Rajdhani Express which covers a distance of 1345 kilometres in approximately 15 Hours 32 Minutes.\n",
       "\n",
       "[Mumbai Central To New Delhi Trains, Time Table, Distance Between ...](https://www.trainspnrstatus.com/trains/mumbai-central-new-delhi)\n",
       "Travel time from Mumbai Central to New Delhi is generally 29 hours and 20 minutes. Travel time for different trains are listed below. Train Number Time; 12925: 23 hours and 15 minutes: 12951: ... \n",
       "12951 Tejas Rajdhani is the fastest train available from Mumbai Central to New Delhi. It takes only 15 hours and 32 minutes to complete the journey.\n",
       "\n",
       "[Mumbai to Delhi by train, bus, flight, taxi from INR 2,970 - Dec ... - 12Go](https://12go.asia/en/travel/mumbai/delhi)\n",
       "The travel time from Mumbai to Delhi can vary depending on the mode of transportation you choose. All things considered, the whole journey should take from 2 to 43 hours. ... Traveling by plane is the\n",
       "fastest way to get from Mumbai to Delhi. While it's often the most expensive option, tool, occasionally you can grab promotional tickets for ...\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "## Search Results\n",
       "\n",
       "[Mumbai to Delhi - 5 ways to travel via train, plane, bus, and car](https://www.rome2rio.com/s/Mumbai/Delhi)\n",
       "The best way to get from Mumbai to Delhi is to fly which takes 3h 57m and costs ₹3,500 - ₹8,000. Alternatively, you can train, which costs ₹600 - ₹17,000 and takes 15h 32m, you could also bus, which \n",
       "costs and takes 29h 12m.\n",
       "\n",
       "[MUMBAI CENTRAL (MMCT) to NEW DELHI (NDLS) Trains: Tickets ... - RailYatri](https://www.railyatri.in/mumbai-central-to-new-delhi-trains)\n",
       "Mumbai Central to New Delhi train time. The Mumbai Central to New Delhi train takes between 15 Hours 32 Minutes to 28 Hours 10 Minutes. The traveller can select a train based on their preferences \n",
       "among every day trains such as Mumbai Central - New Delhi Rajdhani Express (12951), August Kranti Rajdhani Express (12953), Maharashtra Sampark Kranti Express (12907), Mumbai CSMT - Hazrat Nizamuddin \n",
       "...\n",
       "\n",
       "[Mumbai to Delhi - Multiple Options To Reach By Flight ... - MakeMyTrip](https://www.makemytrip.com/routeplanner/mumbai-delhi.html)\n",
       "The fastest way to reach Delhi from Mumbai is by Flight. It takes approximately 3 hours. The cheapest way to reach Delhi from Mumbai is by Train which would take approximately 25 hours. ... Approx \n",
       "Travel Time. 1d 1h 15m ₹605. Onwards. BOOK TRAIN. Via Jaipur. Mumbai. Jaipur. Delhi. Approx Travel Time. 4h 10m ₹9,117. Onwards. Details. Mumbai ...\n",
       "\n",
       "[Mumbai To Delhi Trains | Book From 33 Trains, Timetable, Fare - MakeMyTrip](https://www.makemytrip.com/railways/mumbai-delhi-train-tickets.html)\n",
       "Travel time by train between Mumbai to Delhi is 15h 35m. ... Want to travel from Mumbai to Delhi? Know about the trains running on this route. Some of the trains that run on this route are Hwh CSMT \n",
       "ASR EXPRESS (11057),PUNJAB MAIL (12137),LTT HW AC EXP (12171),DEE GARIBRATH (12216) etc. ... Choose MMT for the best Mumbai to Delhi train ticket ...\n",
       "\n",
       "[Mumbai to Delhi Trains: Here are the Best Ones - TripSavvy](https://www.tripsavvy.com/trains-from-mumbai-to-delhi-1539622)\n",
       "Best Mumbai to Delhi Trains . The 12951 Mumbai Central - New Delhi Rajdhani Express departs Mumbai Central at 5 p.m. and arrives at New Delhi Railway Station at 8.35 a.m. the next morning. There are \n",
       "six stops on the way. The fare in 1AC (first class, air conditioned, sleeper) is 4,760 rupees. 2A (two tier, air conditioned, sleeper) is a minimum of 2,830 rupees and a maximum of 4,073 rupees. 3A \n",
       "...\n",
       "\n",
       "[Mumbai to Delhi Trains | Book from 16 Trains, Fare, Time Table - ixigo](https://www.ixigo.com/by-train-rail/mumbai-to-delhi-by-train)\n",
       "The fastest train to Delhi from Mumbai is 12951 NDLS TEJAS RAJ.From Mumbai, the train takes 15hr 32min hours to reach Delhi. The train starts at 17:00:00 from Mumbai CSTM and reaches Delhi NDLS at \n",
       "08:32:00. 12951 NDLS TEJAS RAJ operates on Mon, Tues, Wed, Thur, Fri, Sat, Sun.\n",
       "\n",
       "[12951 - Mumbai Central New Delhi Rajdhani Express - RailYatri](https://www.railyatri.in/trains/route-12951-mumbai-central-new-delhi-rajdhani-express)\n",
       "This train runs between Mumbai Central to New Delhi and covers a total distance of 1384.0km in just 15h:32m. ... Arrival Time Stop Travel Time; 22209 - Mumbai Central New Delhi Duronto Express: 23:10 \n",
       "15:55 5 16h 45m Popular Trains from Mumbai Central. Train Number and Name ...\n",
       "\n",
       "[MUMBAI CST (CSTM) to NEW DELHI (NDLS) Trains: Tickets, Fare and ...](https://www.railyatri.in/mumbai-cst-to-new-delhi-trains)\n",
       "Mumbai Cst to New Delhi Train Ticket Booking. Mumbai Cst and New Delhi are approximately 1345 kilometers away from one another. The first train from Mumbai Cst to New Delhi leaves at 00:20 hrs from \n",
       "Mumbai Cst.The fastest train from Mumbai Cst to New Delhi is the Mumbai Central - New Delhi Rajdhani Express which covers a distance of 1345 kilometres in approximately 15 Hours 32 Minutes.\n",
       "\n",
       "[Mumbai Central To New Delhi Trains, Time Table, Distance Between ...](https://www.trainspnrstatus.com/trains/mumbai-central-new-delhi)\n",
       "Travel time from Mumbai Central to New Delhi is generally 29 hours and 20 minutes. Travel time for different trains are listed below. Train Number Time; 12925: 23 hours and 15 minutes: 12951: ... \n",
       "12951 Tejas Rajdhani is the fastest train available from Mumbai Central to New Delhi. It takes only 15 hours and 32 minutes to complete the journey.\n",
       "\n",
       "[Mumbai to Delhi by train, bus, flight, taxi from INR 2,970 - Dec ... - 12Go](https://12go.asia/en/travel/mumbai/delhi)\n",
       "The travel time from Mumbai to Delhi can vary depending on the mode of transportation you choose. All things considered, the whole journey should take from 2 to 43 hours. ... Traveling by plane is the\n",
       "fastest way to get from Mumbai to Delhi. While it's often the most expensive option, tool, occasionally you can grab promotional tickets for ...\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 5.07 seconds| Input tokens: 2,068 | Output tokens: 64]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 5.07 seconds| Input tokens: 2,068 | Output tokens: 64]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"3 hours 57 minutes\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                                                              </span> │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m3 hours 57 minutes\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                              \u001b[0m │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: 3 hours 57 minutes</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: 3 hours 57 minutes\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 4.91 seconds| Input tokens: 5,698 | Output tokens: 125]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 4.91 seconds| Input tokens: 5,698 | Output tokens: 125]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'3 hours 57 minutes'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = CodeAgent(tools=[DuckDuckGoSearchTool()], model=model)\n",
    "\n",
    "agent.run(\"how fast can we travel from mumbai to delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">╭────────────────────────────────────────────────────────────────────────────────────────────── </span><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">New run</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ───────────────────────────────────────────────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span> <span style=\"font-weight: bold\">how does OpenAI's O3 model compare to LLama 3.3</span>                                                                                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>                                                                                                                                                                                                      <span style=\"color: #d4b702; text-decoration-color: #d4b702\">│</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702\">╰─ HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m╭─\u001b[0m\u001b[38;2;212;183;2m─────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[1;38;2;212;183;2mNew run\u001b[0m\u001b[38;2;212;183;2m \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╮\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m \u001b[1mhow does OpenAI's O3 model compare to LLama 3.3\u001b[0m                                                                                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m│\u001b[0m                                                                                                                                                                                                      \u001b[38;2;212;183;2m│\u001b[0m\n",
       "\u001b[38;2;212;183;2m╰─\u001b[0m\u001b[38;2;212;183;2m HfApiModel - Qwen/Qwen2.5-Coder-32B-Instruct \u001b[0m\u001b[38;2;212;183;2m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\u001b[38;2;212;183;2m─╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m0\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">openai_o3_results </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_search(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"OpenAI O3 model\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                                         </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">2 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">llama_3_3_results </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> web_search(query</span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"LLama 3.3 model\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">)</span><span style=\"background-color: #272822\">                                                                                                                                         </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">3 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"OpenAI O3 results:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, openai_o3_results)</span><span style=\"background-color: #272822\">                                                                                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">4 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">print(</span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"LLama 3.3 results:\"</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">, llama_3_3_results)</span><span style=\"background-color: #272822\">                                                                                                                                                  </span> │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mopenai_o3_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_search\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mOpenAI O3 model\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                         \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m2 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllama_3_3_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mweb_search\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mquery\u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mLLama 3.3 model\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                         \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m3 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mOpenAI O3 results:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mopenai_o3_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m4 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mprint\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mLLama 3.3 results:\u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m,\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mllama_3_3_results\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                  \u001b[0m │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Execution logs:</span>\n",
       "OpenAI O3 results: ## Search Results\n",
       "\n",
       "[OpenAI o3 - Wikipedia](https://en.wikipedia.org/wiki/OpenAI_o3)\n",
       "OpenAI o3 is a generative pre-trained transformer ... The OpenAI o3 model was announced on December 20, 2024, with the designation \"o3\" chosen to avoid trademark conflict with the existing UK mobile \n",
       "carrier named O2. The model is available in two versions: o3 and o3-mini. OpenAI invited safety and security researchers to apply for early access ...\n",
       "\n",
       "[OpenAI unveils o3 and o3 mini — here's why these models are a giant ...](https://www.tomsguide.com/ai/openai-unveils-o3-and-o3-mini-heres-why-these-reasoning-models-are-a-giant-leap)\n",
       "OpenAI has introduced its latest AI models, o3 and o3-mini, signaling a new chapter for the tech giant. Announced today, the final session of OpenAI's \"12 Days of OpenAI\" event, CEO Sam Altman ...\n",
       "\n",
       "[OpenAI announces new o3 models - TechCrunch](https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/)\n",
       "OpenAI makes the remarkable claim that o3, at least in certain conditions, approaches AGI — with significant caveats. More on that below. o3, our latest reasoning model, is a breakthrough, with ...\n",
       "\n",
       "[The Dawn of a New Era: OpenAI's o3 Model Surpasses the Best of Us](https://theaugmentedmanager.substack.com/p/the-dawn-of-a-new-era-openais-o3)\n",
       "OpenAI's o3 model achieved an Elo score of 2727, placing it firmly within this elite group. This performance means that o3 surpassed the 99.95th percentile of human coders, a level of expertise that \n",
       "includes some of OpenAI's own top researchers. The significance of this achievement lies not only in the raw score but in what it represents ...\n",
       "\n",
       "[OpenAI Unveils New O3 Model: What Is It and How Is It Different from O1?](https://www.helicone.ai/blog/openai-o3)\n",
       "Introducing O3-Mini: A More Adaptive Model. Alongside the o3 model, OpenAI also unveiled the o3-mini. This version is more lightweight and offers an adaptive thinking time feature, allowing users to \n",
       "select low, medium, or high processing speeds depending on their needs. The o3-mini is designed for situations where you might not need the full ...\n",
       "\n",
       "[OpenAI o3 Model Is a Message From the Future: Update All You Think You ...](https://www.thealgorithmicbridge.com/p/openai-o3-model-is-a-message-from)\n",
       "For context, ARC-AGI-1 [this benchmark] took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3. . . . OpenAI's new\n",
       "o3 model represents a significant leap forward in AI's ability to adapt to novel tasks.\n",
       "\n",
       "[OpenAI's ChatGPT o3 Model Promises Better Reasoning - Lifehacker](https://lifehacker.com/tech/openai-promises-chatgpt-o3-model-better-at-reasoning)\n",
       "The o3 model is more than 20 percent better than the previous o1 model at coding, per the SWE-bench Verified benchmark, OpenAI says. It also scores strongly on math and science problems, at least ...\n",
       "\n",
       "[OpenAI unveils new o3 model: What is it and how is it different from o1?](https://indianexpress.com/article/explained/explained-sci-tech/openai-new-o3-model-9737712/)\n",
       "The model's low-effort reasoning offers speed and efficiency needed for simple tasks, and for complex tasks, it uses higher effort for accuracy. The high-effort mode matches the larger o3 model but at\n",
       "a significantly lower cost. According to OpenAI, the flexibility of the o3 Mini model makes it best suited for developers and researchers.\n",
       "\n",
       "[OpenAI Unveils o3 System That Reasons Through Math, Science Problems ...](https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html)\n",
       "OpenAI on Friday unveiled a new artificial intelligence system, OpenAI o3, which is designed to \"reason\" through problems involving math, science and computer programming. ... \"This model is ...\n",
       "\n",
       "[OpenAI Upgrades Its Smartest AI Model With Improved Reasoning Skills](https://www.wired.com/story/openai-o3-reasoning-model-google-gemini/)\n",
       "OpenAI says there are two versions of the new model, o3 and o3-mini. The company is not making the models publicly available yet but says it will invite outsiders to apply to perform testing of them.\n",
       "LLama 3.3 results: ## Search Results\n",
       "\n",
       "[Llama 3.3 | Model Cards and Prompt formats](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_3/)\n",
       "Llama 3.3 is a text-only 70B instruction-tuned model that provides enhanced performance relative to Llama 3.1 70B-and to Llama 3.2 90B when used for text-only applications.\n",
       "\n",
       "[The new Llama 3.3 70B model has just dropped - Tom's Guide](https://www.tomsguide.com/ai/the-new-llama-3-3-70b-model-has-just-dropped-heres-why-its-a-big-deal)\n",
       "The new model is available for download and installation at Ollama, Hugging Face or at Meta's official Llama site. Why is Llama 3.3 70b a big deal? (Image credit: Meta AI)\n",
       "\n",
       "[llama-models/models/llama3_3/MODEL_CARD.md at main - GitHub](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)\n",
       "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is \n",
       "optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n",
       "\n",
       "[Llama 3.3 Requirements [What do you Need to Use It?]](https://llamaimodel.com/requirements-3-3/)\n",
       "Llama 3.3 represents a significant advancement in the field of AI language models. With a single variant boasting 70 billion parameters, this model delivers efficient and powerful solutions for a wide\n",
       "range of applications, from edge devices to large-scale cloud deployments. Llama 3.3 70B Requirements Category Requirement Details Model Specifications Parameters 70 billion Context Length ...\n",
       "\n",
       "[How to Use Llama 3.3 70B: A Comprehensive Guide](https://www.hyperstack.cloud/technical-resources/tutorials/how-to-use-llama-3-3-a-comprehensive-guide)\n",
       "Check out the latest tutorial below to deploy the Llama 3.3 70B model on Hyperstack. What is Llama 3.3? Llama 3.3 is a 70-billion parameter model optimised for instruction-following and text-based \n",
       "tasks. It outperforms Llama 3.1 70B and Llama 3.2 90B and even competes with the larger Llama 3.1 405B in some tasks. Unlike earlier models, Llama 3. ...\n",
       "\n",
       "[Meta launches Llama 3.3, shrinking powerful 405B open model - VentureBeat](https://venturebeat.com/ai/meta-launches-open-source-llama-3-3-shrinking-powerful-bigger-model-into-smaller-size/)\n",
       "Meta's Llama 3.3 is offered under the Llama 3.3 Community License Agreement, which grants a non-exclusive, royalty-free license for use, reproduction, distribution, and modification of the model ...\n",
       "\n",
       "[Announcing the new Meta Llama 3.3 model on Databricks](https://community.databricks.com/t5/announcements/announcing-the-new-meta-llama-3-3-model-on-databricks/td-p/101855)\n",
       "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is \n",
       "optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n",
       "\n",
       "[Meta's Llama 3.3: The Evolution of Open-Source Large ... - Medium](https://medium.com/majordigest/metas-llama-3-3-the-evolution-of-open-source-large-language-models-c9395bde587b)\n",
       "1. Model Overview. Llama 3.3 comes in 70 billion (70B) parameter variants. The model has been trained on a massive dataset of 15 trillion tokens, a substantial increase from the 2 trillion tokens ...\n",
       "\n",
       "[How to Run Meta's Llama-3.3 Locally: A Step-by-Step Guide](https://pub.towardsai.net/how-to-run-metas-llama-3-3-locally-a-step-by-step-guide-c21ba38cf9a4)\n",
       "Meta's Llama-3.3, the latest multilingual large language model, has captured attention for its cutting-edge capabilities in text generation, instruction following, and multilingual communication. \n",
       "Running Llama-3.3 locally unlocks its full potential for applications like chatbots, content generation, and advanced research assistance.\n",
       "\n",
       "[Llama 3.3 70B AI Model Performance Tested - Geeky Gadgets](https://www.geeky-gadgets.com/llama-3-3-70-review/)\n",
       "The Llama 3.3 70B AI model features a 128k token context window, ethical alignment, and text-in, text-out interaction, making it versatile for technical and creative tasks.\n",
       "\n",
       "Out: None\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mExecution logs:\u001b[0m\n",
       "OpenAI O3 results: ## Search Results\n",
       "\n",
       "[OpenAI o3 - Wikipedia](https://en.wikipedia.org/wiki/OpenAI_o3)\n",
       "OpenAI o3 is a generative pre-trained transformer ... The OpenAI o3 model was announced on December 20, 2024, with the designation \"o3\" chosen to avoid trademark conflict with the existing UK mobile \n",
       "carrier named O2. The model is available in two versions: o3 and o3-mini. OpenAI invited safety and security researchers to apply for early access ...\n",
       "\n",
       "[OpenAI unveils o3 and o3 mini — here's why these models are a giant ...](https://www.tomsguide.com/ai/openai-unveils-o3-and-o3-mini-heres-why-these-reasoning-models-are-a-giant-leap)\n",
       "OpenAI has introduced its latest AI models, o3 and o3-mini, signaling a new chapter for the tech giant. Announced today, the final session of OpenAI's \"12 Days of OpenAI\" event, CEO Sam Altman ...\n",
       "\n",
       "[OpenAI announces new o3 models - TechCrunch](https://techcrunch.com/2024/12/20/openai-announces-new-o3-model/)\n",
       "OpenAI makes the remarkable claim that o3, at least in certain conditions, approaches AGI — with significant caveats. More on that below. o3, our latest reasoning model, is a breakthrough, with ...\n",
       "\n",
       "[The Dawn of a New Era: OpenAI's o3 Model Surpasses the Best of Us](https://theaugmentedmanager.substack.com/p/the-dawn-of-a-new-era-openais-o3)\n",
       "OpenAI's o3 model achieved an Elo score of 2727, placing it firmly within this elite group. This performance means that o3 surpassed the 99.95th percentile of human coders, a level of expertise that \n",
       "includes some of OpenAI's own top researchers. The significance of this achievement lies not only in the raw score but in what it represents ...\n",
       "\n",
       "[OpenAI Unveils New O3 Model: What Is It and How Is It Different from O1?](https://www.helicone.ai/blog/openai-o3)\n",
       "Introducing O3-Mini: A More Adaptive Model. Alongside the o3 model, OpenAI also unveiled the o3-mini. This version is more lightweight and offers an adaptive thinking time feature, allowing users to \n",
       "select low, medium, or high processing speeds depending on their needs. The o3-mini is designed for situations where you might not need the full ...\n",
       "\n",
       "[OpenAI o3 Model Is a Message From the Future: Update All You Think You ...](https://www.thealgorithmicbridge.com/p/openai-o3-model-is-a-message-from)\n",
       "For context, ARC-AGI-1 [this benchmark] took 4 years to go from 0% with GPT-3 in 2020 to 5% in 2024 with GPT-4o. All intuition about AI capabilities will need to get updated for o3. . . . OpenAI's new\n",
       "o3 model represents a significant leap forward in AI's ability to adapt to novel tasks.\n",
       "\n",
       "[OpenAI's ChatGPT o3 Model Promises Better Reasoning - Lifehacker](https://lifehacker.com/tech/openai-promises-chatgpt-o3-model-better-at-reasoning)\n",
       "The o3 model is more than 20 percent better than the previous o1 model at coding, per the SWE-bench Verified benchmark, OpenAI says. It also scores strongly on math and science problems, at least ...\n",
       "\n",
       "[OpenAI unveils new o3 model: What is it and how is it different from o1?](https://indianexpress.com/article/explained/explained-sci-tech/openai-new-o3-model-9737712/)\n",
       "The model's low-effort reasoning offers speed and efficiency needed for simple tasks, and for complex tasks, it uses higher effort for accuracy. The high-effort mode matches the larger o3 model but at\n",
       "a significantly lower cost. According to OpenAI, the flexibility of the o3 Mini model makes it best suited for developers and researchers.\n",
       "\n",
       "[OpenAI Unveils o3 System That Reasons Through Math, Science Problems ...](https://www.nytimes.com/2024/12/20/technology/openai-new-ai-math-science.html)\n",
       "OpenAI on Friday unveiled a new artificial intelligence system, OpenAI o3, which is designed to \"reason\" through problems involving math, science and computer programming. ... \"This model is ...\n",
       "\n",
       "[OpenAI Upgrades Its Smartest AI Model With Improved Reasoning Skills](https://www.wired.com/story/openai-o3-reasoning-model-google-gemini/)\n",
       "OpenAI says there are two versions of the new model, o3 and o3-mini. The company is not making the models publicly available yet but says it will invite outsiders to apply to perform testing of them.\n",
       "LLama 3.3 results: ## Search Results\n",
       "\n",
       "[Llama 3.3 | Model Cards and Prompt formats](https://www.llama.com/docs/model-cards-and-prompt-formats/llama3_3/)\n",
       "Llama 3.3 is a text-only 70B instruction-tuned model that provides enhanced performance relative to Llama 3.1 70B-and to Llama 3.2 90B when used for text-only applications.\n",
       "\n",
       "[The new Llama 3.3 70B model has just dropped - Tom's Guide](https://www.tomsguide.com/ai/the-new-llama-3-3-70b-model-has-just-dropped-heres-why-its-a-big-deal)\n",
       "The new model is available for download and installation at Ollama, Hugging Face or at Meta's official Llama site. Why is Llama 3.3 70b a big deal? (Image credit: Meta AI)\n",
       "\n",
       "[llama-models/models/llama3_3/MODEL_CARD.md at main - GitHub](https://github.com/meta-llama/llama-models/blob/main/models/llama3_3/MODEL_CARD.md)\n",
       "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is \n",
       "optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n",
       "\n",
       "[Llama 3.3 Requirements [What do you Need to Use It?]](https://llamaimodel.com/requirements-3-3/)\n",
       "Llama 3.3 represents a significant advancement in the field of AI language models. With a single variant boasting 70 billion parameters, this model delivers efficient and powerful solutions for a wide\n",
       "range of applications, from edge devices to large-scale cloud deployments. Llama 3.3 70B Requirements Category Requirement Details Model Specifications Parameters 70 billion Context Length ...\n",
       "\n",
       "[How to Use Llama 3.3 70B: A Comprehensive Guide](https://www.hyperstack.cloud/technical-resources/tutorials/how-to-use-llama-3-3-a-comprehensive-guide)\n",
       "Check out the latest tutorial below to deploy the Llama 3.3 70B model on Hyperstack. What is Llama 3.3? Llama 3.3 is a 70-billion parameter model optimised for instruction-following and text-based \n",
       "tasks. It outperforms Llama 3.1 70B and Llama 3.2 90B and even competes with the larger Llama 3.1 405B in some tasks. Unlike earlier models, Llama 3. ...\n",
       "\n",
       "[Meta launches Llama 3.3, shrinking powerful 405B open model - VentureBeat](https://venturebeat.com/ai/meta-launches-open-source-llama-3-3-shrinking-powerful-bigger-model-into-smaller-size/)\n",
       "Meta's Llama 3.3 is offered under the Llama 3.3 Community License Agreement, which grants a non-exclusive, royalty-free license for use, reproduction, distribution, and modification of the model ...\n",
       "\n",
       "[Announcing the new Meta Llama 3.3 model on Databricks](https://community.databricks.com/t5/announcements/announcing-the-new-meta-llama-3-3-model-on-databricks/td-p/101855)\n",
       "The Meta Llama 3.3 multilingual large language model (LLM) is a pretrained and instruction tuned generative model in 70B (text in/text out). The Llama 3.3 instruction tuned text only model is \n",
       "optimized for multilingual dialogue use cases and outperforms many of the available open source and closed chat models on common industry benchmarks.\n",
       "\n",
       "[Meta's Llama 3.3: The Evolution of Open-Source Large ... - Medium](https://medium.com/majordigest/metas-llama-3-3-the-evolution-of-open-source-large-language-models-c9395bde587b)\n",
       "1. Model Overview. Llama 3.3 comes in 70 billion (70B) parameter variants. The model has been trained on a massive dataset of 15 trillion tokens, a substantial increase from the 2 trillion tokens ...\n",
       "\n",
       "[How to Run Meta's Llama-3.3 Locally: A Step-by-Step Guide](https://pub.towardsai.net/how-to-run-metas-llama-3-3-locally-a-step-by-step-guide-c21ba38cf9a4)\n",
       "Meta's Llama-3.3, the latest multilingual large language model, has captured attention for its cutting-edge capabilities in text generation, instruction following, and multilingual communication. \n",
       "Running Llama-3.3 locally unlocks its full potential for applications like chatbots, content generation, and advanced research assistance.\n",
       "\n",
       "[Llama 3.3 70B AI Model Performance Tested - Geeky Gadgets](https://www.geeky-gadgets.com/llama-3-3-70-review/)\n",
       "The Llama 3.3 70B AI model features a 128k token context window, ethical alignment, and text-in, text-out interaction, making it versatile for technical and creative tasks.\n",
       "\n",
       "Out: None\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 0: Duration 7.48 seconds| Input tokens: 2,073 | Output tokens: 116]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 0: Duration 7.48 seconds| Input tokens: 2,073 | Output tokens: 116]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ </span><span style=\"font-weight: bold\">Step </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #d4b702; text-decoration-color: #d4b702\"> ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;212;183;2m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ \u001b[0m\u001b[1mStep \u001b[0m\u001b[1;36m1\u001b[0m\u001b[38;2;212;183;2m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">╭─ <span style=\"font-weight: bold\">Executing this code:</span> ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 1 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">comparison </span><span style=\"color: #ff4689; text-decoration-color: #ff4689; background-color: #272822\">=</span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\"> </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"</span><span style=\"background-color: #272822\">                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 2 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">Comparison of OpenAI O3 and LLama 3.3:</span><span style=\"background-color: #272822\">                                                                                                                                                         </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 3 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 4 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Announcement Date:**</span><span style=\"background-color: #272822\">                                                                                                                                                                       </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 5 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: December 20, 2024</span><span style=\"background-color: #272822\">                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 6 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: No specific mention in the search results (assumed to be recent)</span><span style=\"background-color: #272822\">                                                                                                                </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 7 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 8 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Model Variants:**</span><span style=\"background-color: #272822\">                                                                                                                                                                          </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\"> 9 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: o3 and o3-mini</span><span style=\"background-color: #272822\">                                                                                                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">10 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Single 70B parameter model</span><span style=\"background-color: #272822\">                                                                                                                                                      </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">11 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">12 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Applications:**</span><span style=\"background-color: #272822\">                                                                                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">13 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: General-purpose AI with an emphasis on better reasoning in coding, math, and science problems.</span><span style=\"background-color: #272822\">                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">14 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Text-only applications with a focus on multilingual dialogue use cases.</span><span style=\"background-color: #272822\">                                                                                                         </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">15 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">16 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Performance:**</span><span style=\"background-color: #272822\">                                                                                                                                                                             </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">17 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Improved reasoning, strong performance on coding and scientific tasks.</span><span style=\"background-color: #272822\">                                                                                                          </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">18 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Enhanced performance relative to 3.1 and 3.2, better on common industry benchmarks.</span><span style=\"background-color: #272822\">                                                                                             </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">19 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">20 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Adaptability:**</span><span style=\"background-color: #272822\">                                                                                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">21 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Adaptive thinking time feature (o3-mini can adjust processing speed).</span><span style=\"background-color: #272822\">                                                                                                           </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">22 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Single variant with adaptive capabilities likely tied to its design.</span><span style=\"background-color: #272822\">                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">23 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">24 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Ethical Considerations:**</span><span style=\"background-color: #272822\">                                                                                                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">25 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Not specifically mentioned.</span><span style=\"background-color: #272822\">                                                                                                                                                     </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">26 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Includes ethical alignment.</span><span style=\"background-color: #272822\">                                                                                                                                                     </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">27 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">28 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Context Window:**</span><span style=\"background-color: #272822\">                                                                                                                                                                          </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">29 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Not specifically mentioned.</span><span style=\"background-color: #272822\">                                                                                                                                                     </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">30 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: 128k token context window</span><span style=\"background-color: #272822\">                                                                                                                                                       </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">31 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">32 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Design:**</span><span style=\"background-color: #272822\">                                                                                                                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">33 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Designed for both simple and complex tasks.</span><span style=\"background-color: #272822\">                                                                                                                                     </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">34 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Optimized for multilingual dialogue.</span><span style=\"background-color: #272822\">                                                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">35 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">36 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Parameter Count:**</span><span style=\"background-color: #272822\">                                                                                                                                                                         </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">37 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Not specified in the provided results.</span><span style=\"background-color: #272822\">                                                                                                                                          </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">38 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: 70B parameters</span><span style=\"background-color: #272822\">                                                                                                                                                                  </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">39 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">40 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">- **Availability:**</span><span style=\"background-color: #272822\">                                                                                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">41 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - OpenAI O3: Public availability not yet mentioned.</span><span style=\"background-color: #272822\">                                                                                                                                          </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">42 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">  - LLama 3.3: Available for download and installation at various platforms.</span><span style=\"background-color: #272822\">                                                                                                                   </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">43 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">44 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">This comparison is based on the available information up to the latest updates in the searches performed.</span><span style=\"background-color: #272822\">                                                                                      </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">45 </span><span style=\"color: #e6db74; text-decoration-color: #e6db74; background-color: #272822\">\"\"\"</span><span style=\"background-color: #272822\">                                                                                                                                                                                            </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">46 </span><span style=\"background-color: #272822\">                                                                                                                                                                                               </span> │\n",
       "│ <span style=\"color: #e3e3dd; text-decoration-color: #e3e3dd; background-color: #272822; font-weight: bold\">  </span><span style=\"color: #656660; text-decoration-color: #656660; background-color: #272822\">47 </span><span style=\"color: #f8f8f2; text-decoration-color: #f8f8f2; background-color: #272822\">final_answer(comparison)</span><span style=\"background-color: #272822\">                                                                                                                                                                       </span> │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n",
       "</pre>\n"
      ],
      "text/plain": [
       "╭─ \u001b[1mExecuting this code:\u001b[0m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 1 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcomparison\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;255;70;137;48;2;39;40;34m=\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 2 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mComparison of OpenAI O3 and LLama 3.3:\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                         \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 3 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 4 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Announcement Date:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                       \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 5 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: December 20, 2024\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 6 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: No specific mention in the search results (assumed to be recent)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 7 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 8 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Model Variants:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                          \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m 9 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: o3 and o3-mini\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m10 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Single 70B parameter model\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                      \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m11 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m12 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Applications:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m13 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: General-purpose AI with an emphasis on better reasoning in coding, math, and science problems.\u001b[0m\u001b[48;2;39;40;34m                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m14 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Text-only applications with a focus on multilingual dialogue use cases.\u001b[0m\u001b[48;2;39;40;34m                                                                                                         \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m15 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m16 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Performance:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                             \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m17 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Improved reasoning, strong performance on coding and scientific tasks.\u001b[0m\u001b[48;2;39;40;34m                                                                                                          \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m18 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Enhanced performance relative to 3.1 and 3.2, better on common industry benchmarks.\u001b[0m\u001b[48;2;39;40;34m                                                                                             \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m19 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m20 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Adaptability:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m21 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Adaptive thinking time feature (o3-mini can adjust processing speed).\u001b[0m\u001b[48;2;39;40;34m                                                                                                           \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m22 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Single variant with adaptive capabilities likely tied to its design.\u001b[0m\u001b[48;2;39;40;34m                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m23 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m24 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Ethical Considerations:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m25 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Not specifically mentioned.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                     \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m26 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Includes ethical alignment.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                     \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m27 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m28 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Context Window:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                          \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m29 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Not specifically mentioned.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                     \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m30 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: 128k token context window\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                       \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m31 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m32 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Design:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m33 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Designed for both simple and complex tasks.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                     \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m34 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Optimized for multilingual dialogue.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m35 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m36 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Parameter Count:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                         \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m37 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Not specified in the provided results.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                          \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m38 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: 70B parameters\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                  \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m39 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m40 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m- **Availability:**\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m41 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - OpenAI O3: Public availability not yet mentioned.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                          \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m42 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m  - LLama 3.3: Available for download and installation at various platforms.\u001b[0m\u001b[48;2;39;40;34m                                                                                                                   \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m43 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m44 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34mThis comparison is based on the available information up to the latest updates in the searches performed.\u001b[0m\u001b[48;2;39;40;34m                                                                                      \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m45 \u001b[0m\u001b[38;2;230;219;116;48;2;39;40;34m\"\"\"\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                            \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m46 \u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                                               \u001b[0m │\n",
       "│ \u001b[1;38;2;227;227;221;48;2;39;40;34m  \u001b[0m\u001b[38;2;101;102;96;48;2;39;40;34m47 \u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mfinal_answer\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m(\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34mcomparison\u001b[0m\u001b[38;2;248;248;242;48;2;39;40;34m)\u001b[0m\u001b[48;2;39;40;34m                                                                                                                                                                       \u001b[0m │\n",
       "╰──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Out - Final answer: </span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">Comparison of OpenAI O3 and LLama 3.3:</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Announcement Date:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: December 20, 2024</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: No specific mention in the search results (assumed to be recent)</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Model Variants:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: o3 and o3-mini</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Single 70B parameter model</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Applications:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: General-purpose AI with an emphasis on better reasoning in coding, math, and science problems.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Text-only applications with a focus on multilingual dialogue use cases.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Performance:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Improved reasoning, strong performance on coding and scientific tasks.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Enhanced performance relative to 3.1 and 3.2, better on common industry benchmarks.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Adaptability:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Adaptive thinking time feature (o3-mini can adjust processing speed).</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Single variant with adaptive capabilities likely tied to its design.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Ethical Considerations:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Not specifically mentioned.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Includes ethical alignment.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Context Window:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Not specifically mentioned.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: 128k token context window</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Design:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Designed for both simple and complex tasks.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Optimized for multilingual dialogue.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Parameter Count:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Not specified in the provided results.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: 70B parameters</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">- **Availability:**</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - OpenAI O3: Public availability not yet mentioned.</span>\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">  - LLama 3.3: Available for download and installation at various platforms.</span>\n",
       "\n",
       "<span style=\"color: #d4b702; text-decoration-color: #d4b702; font-weight: bold\">This comparison is based on the available information up to the latest updates in the searches performed.</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;2;212;183;2mOut - Final answer: \u001b[0m\n",
       "\u001b[1;38;2;212;183;2mComparison of OpenAI O3 and LLama 3.3:\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Announcement Date:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: December 20, 2024\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: No specific mention in the search results (assumed to be recent)\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Model Variants:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: o3 and o3-mini\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Single 70B parameter model\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Applications:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: General-purpose AI with an emphasis on better reasoning in coding, math, and science problems.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Text-only applications with a focus on multilingual dialogue use cases.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Performance:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Improved reasoning, strong performance on coding and scientific tasks.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Enhanced performance relative to 3.1 and 3.2, better on common industry benchmarks.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Adaptability:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Adaptive thinking time feature (o3-mini can adjust processing speed).\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Single variant with adaptive capabilities likely tied to its design.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Ethical Considerations:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Not specifically mentioned.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Includes ethical alignment.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Context Window:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Not specifically mentioned.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: 128k token context window\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Design:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Designed for both simple and complex tasks.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Optimized for multilingual dialogue.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Parameter Count:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Not specified in the provided results.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: 70B parameters\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2m- **Availability:**\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - OpenAI O3: Public availability not yet mentioned.\u001b[0m\n",
       "\u001b[1;38;2;212;183;2m  - LLama 3.3: Available for download and installation at various platforms.\u001b[0m\n",
       "\n",
       "\u001b[1;38;2;212;183;2mThis comparison is based on the available information up to the latest updates in the searches performed.\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">[Step 1: Duration 26.21 seconds| Input tokens: 6,606 | Output tokens: 796]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2m[Step 1: Duration 26.21 seconds| Input tokens: 6,606 | Output tokens: 796]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\nComparison of OpenAI O3 and LLama 3.3:\\n\\n- **Announcement Date:**\\n  - OpenAI O3: December 20, 2024\\n  - LLama 3.3: No specific mention in the search results (assumed to be recent)\\n\\n- **Model Variants:**\\n  - OpenAI O3: o3 and o3-mini\\n  - LLama 3.3: Single 70B parameter model\\n\\n- **Applications:**\\n  - OpenAI O3: General-purpose AI with an emphasis on better reasoning in coding, math, and science problems.\\n  - LLama 3.3: Text-only applications with a focus on multilingual dialogue use cases.\\n\\n- **Performance:**\\n  - OpenAI O3: Improved reasoning, strong performance on coding and scientific tasks.\\n  - LLama 3.3: Enhanced performance relative to 3.1 and 3.2, better on common industry benchmarks.\\n\\n- **Adaptability:**\\n  - OpenAI O3: Adaptive thinking time feature (o3-mini can adjust processing speed).\\n  - LLama 3.3: Single variant with adaptive capabilities likely tied to its design.\\n\\n- **Ethical Considerations:**\\n  - OpenAI O3: Not specifically mentioned.\\n  - LLama 3.3: Includes ethical alignment.\\n\\n- **Context Window:**\\n  - OpenAI O3: Not specifically mentioned.\\n  - LLama 3.3: 128k token context window\\n\\n- **Design:**\\n  - OpenAI O3: Designed for both simple and complex tasks.\\n  - LLama 3.3: Optimized for multilingual dialogue.\\n\\n- **Parameter Count:**\\n  - OpenAI O3: Not specified in the provided results.\\n  - LLama 3.3: 70B parameters\\n\\n- **Availability:**\\n  - OpenAI O3: Public availability not yet mentioned.\\n  - LLama 3.3: Available for download and installation at various platforms.\\n\\nThis comparison is based on the available information up to the latest updates in the searches performed.\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"how does OpenAI's O3 model compare to LLama 3.3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
