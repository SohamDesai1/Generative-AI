{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq(\n",
    "    api_key=api,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs (Large Language Models) are a type of artificial intelligence (AI) model that are designed to process and understand human language. They are trained on vast amounts of text data and can generate human-like language outputs.\n",
      "\n",
      "Here are some key characteristics of LLMs:\n",
      "\n",
      "1. **Large scale**: LLMs are trained on massive datasets of text, often consisting of billions of parameters.\n",
      "2. **Language understanding**: LLMs are designed to understand nuances of human language, including syntax, semantics, and pragmatics.\n",
      "3. **Generation capabilities**: LLMs can generate human-like text, including articles, stories, conversations, and even entire books.\n",
      "4. **Fine-tuning**: LLMs can be fine-tuned for specific tasks, such as language translation, question answering, and text summarization.\n",
      "5. **State-of-the-art performance**: LLMs have achieved state-of-the-art results in many natural language processing (NLP) tasks, surpassing previous models.\n",
      "\n",
      "Some examples of LLMs include:\n",
      "\n",
      "1. **BERT (Bidirectional Encoder Representations from Transformers)**: Developed by Google in 2018, BERT is a powerful LLM that has achieved state-of-the-art results in many NLP tasks.\n",
      "2. **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: Developed by Facebook AI in 2019, RoBERTa is a variant of BERT that has achieved even better results in some NLP tasks.\n",
      "3. **Transformers**: Developed by the paper \"Attention is All You Need\" in 2017, Transformers are a type of LLM that use self-attention mechanisms to process input sequences.\n",
      "\n",
      "Applications of LLMs include:\n",
      "\n",
      "1. **Chatbots and conversational AI**: LLMs can be used to generate human-like responses in chatbots and conversational AI systems.\n",
      "2. **Language translation**: LLMs can be fine-tuned for language translation tasks, enabling accurate and fluent translations.\n",
      "3. **Text summarization**: LLMs can summarize long documents and articles, extracting key points and main ideas.\n",
      "4. **Content generation**: LLMs can generate high-quality content, such as articles, blog posts, and even entire books.\n",
      "\n",
      "While LLMs have many benefits, they also raise concerns about:\n",
      "\n",
      "1. **Bias and fairness**: LLMs can perpetuate biases present in the training data, leading to unfair or discriminatory outcomes.\n",
      "2. **Lack of transparency**: LLMs can be difficult to interpret, making it challenging to understand their decision-making processes.\n",
      "3. **Job displacement**: The automation of certain tasks by LLMs may lead to job displacement in industries such as customer service and content creation.\n",
      "\n",
      "Overall, LLMs have the potential to revolutionize the field of NLP and enable innovative applications, but it's essential to address the challenges and ethical considerations surrounding their development and deployment.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What are LLMs in AI\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA (Learning to Rank) is a crucial concept in Artificial Intelligence (AI), particularly in the realm of Information Retrieval (IR) and Natural Language Processing (NLP). Here's why LoRA is important in AI:\n",
      "\n",
      "**What is LoRA?**\n",
      "LoRA is a machine learning approach that focuses on ranking models, which are essential in various AI applications, such as search engines, recommender systems, and question-answering systems. The primary goal of LoRA is to learn a ranking function that can accurately predict the relevance or preference of items (e.g., documents, products, or answers) in a list.\n",
      "\n",
      "**Importance of LoRA in AI:**\n",
      "\n",
      "1. **Improved Search Engine Results**: LoRA helps search engines like Google, Bing, or Yahoo to rank web pages in a way that provides the most relevant results to users. This leads to a better user experience and increased user satisfaction.\n",
      "2. **Personalized Recommendations**: In recommender systems, LoRA enables personalized recommendations for users based on their preferences, behavior, and interests. This is crucial in e-commerce, online advertising, and content streaming services.\n",
      "3. **Enhanced Question-Answering Systems**: LoRA is used in question-answering systems to rank potential answers to a user's query. This ensures that the most relevant and accurate answers are presented to the user.\n",
      "4. **Efficient Information Retrieval**: LoRA facilitates efficient information retrieval by ranking documents or data points based on their relevance to a query or topic. This is essential in applications like document retrieval, sentiment analysis, and text classification.\n",
      "5. **Improved User Experience**: By providing accurate rankings, LoRA contributes to a better user experience in various AI applications, such as chatbots, virtual assistants, and voice assistants.\n",
      "6. **Handling Large Datasets**: LoRA is designed to handle large datasets, making it an essential component in big data analytics, data mining, and machine learning applications.\n",
      "7. **Flexibility and Adaptability**: LoRA models can be adapted to various domains, datasets, and applications, making them a versatile tool in AI research and development.\n",
      "\n",
      "In summary, LoRA plays a vital role in AI by enabling accurate ranking, personalized recommendations, and efficient information retrieval, ultimately leading to improved user experiences and more effective AI applications.\n"
     ]
    }
   ],
   "source": [
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"you are a helpful assistant. Answer all the things correctly and as accurate as possible. If you dont know the answer of any of the questions than just reply I dont know refrain from providing false information\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Explain the importance of LoRA in AI\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3-70b-8192\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stop=None,\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
